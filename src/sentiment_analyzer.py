import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F
import numpy as np
import re
import warnings
import logging
from pathlib import Path
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))
from config.settings import *

warnings.filterwarnings("ignore")
logger = logging.getLogger(__name__)

class SentimentAnalyzer:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"Using device: {self.device}")
        logger.info("ğŸ¯ AI ì—­í•  ë¶„ë‹´: KR-FinBERT(1ë‹¨ê³„: ê°ì„±ë¶„ì„) + EXAONE(2ë‹¨ê³„: íˆ¬ìì¸ì‚¬ì´íŠ¸)")
        
        # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(FINBERT_LOCAL_PATH, exist_ok=True)
        os.makedirs(EXAONE_LOCAL_PATH, exist_ok=True)
        
        # KR-FinBERT ì´ˆê¸°í™” (1ë‹¨ê³„: í•œêµ­ì–´ ê¸ˆìœµ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì „ë¬¸)
        self._init_kr_finbert_local()
        
        # EXAONE ì´ˆê¸°í™” (2ë‹¨ê³„: ê°ì„± ê²°ê³¼ + ì°¨íŠ¸ â†’ íˆ¬ì ì¸ì‚¬ì´íŠ¸)
        self._init_exaone_local()
    
    def _is_model_downloaded(self, model_path):
        """ëª¨ë¸ì´ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        model_path = Path(model_path)
        
        required_files = [
            "config.json",
            "tokenizer_config.json"
        ]
        
        model_files = [
            "pytorch_model.bin",
            "model.safetensors",
            "pytorch_model-00001-of-00001.bin"
        ]
        
        for file in required_files:
            if not (model_path / file).exists():
                return False
        
        has_model_file = any((model_path / file).exists() for file in model_files)
        
        return has_model_file
    
    def _init_kr_finbert_local(self):
        """KR-FinBERT ëª¨ë¸ ë¡œì»¬ ì €ì¥ ë° ë¡œë“œ (í•œêµ­ì–´ ê¸ˆìœµ ë‰´ìŠ¤ íŠ¹í™”)"""
        try:
            logger.info("ğŸ¯ 1ë‹¨ê³„: Loading KR-FinBERT for Korean financial news sentiment analysis...")
            
            if self._is_model_downloaded(FINBERT_LOCAL_PATH):
                logger.info("Loading KR-FinBERT from local storage...")
                self.kr_finbert_tokenizer = AutoTokenizer.from_pretrained(str(FINBERT_LOCAL_PATH))
                self.kr_finbert_model = AutoModelForSequenceClassification.from_pretrained(str(FINBERT_LOCAL_PATH)).to(self.device)
            else:
                logger.info("Downloading and saving KR-FinBERT locally...")
                self.kr_finbert_tokenizer = AutoTokenizer.from_pretrained(FINBERT_MODEL)
                self.kr_finbert_model = AutoModelForSequenceClassification.from_pretrained(FINBERT_MODEL).to(self.device)
                
                # ë¡œì»¬ì— ì €ì¥
                self.kr_finbert_tokenizer.save_pretrained(str(FINBERT_LOCAL_PATH))
                self.kr_finbert_model.save_pretrained(str(FINBERT_LOCAL_PATH))
                logger.info(f"KR-FinBERT saved to: {FINBERT_LOCAL_PATH}")
            
            self.kr_finbert_model.eval()
            logger.info("âœ… Successfully loaded KR-FinBERT (Korean Financial News Sentiment Specialist)")
            self.kr_finbert_available = True
            
        except Exception as e:
            logger.error(f"âŒ Error loading KR-FinBERT: {e}")
            self.kr_finbert_available = False
    
    def _init_exaone_local(self):
        """EXAONE ëª¨ë¸ ë¡œì»¬ ì €ì¥ ë° ë¡œë“œ (íˆ¬ì ì¸ì‚¬ì´íŠ¸ ìƒì„±)"""
        try:
            logger.info("ğŸ§  2ë‹¨ê³„: Loading EXAONE for investment insights generation...")
            
            if self._is_model_downloaded(EXAONE_LOCAL_PATH):
                logger.info("Loading EXAONE from local storage...")
                self.exaone_tokenizer = AutoTokenizer.from_pretrained(
                    str(EXAONE_LOCAL_PATH),
                    trust_remote_code=True
                )
                self.exaone_model = AutoModelForCausalLM.from_pretrained(
                    str(EXAONE_LOCAL_PATH),
                    torch_dtype=torch.bfloat16,
                    device_map="auto",
                    max_memory={0: MAX_GPU_MEMORY},
                    low_cpu_mem_usage=True,
                    attn_implementation="eager",
                    trust_remote_code=True
                )
            else:
                logger.info("Downloading and saving EXAONE locally...")
                self.exaone_tokenizer = AutoTokenizer.from_pretrained(
                    EXAONE_MODEL,
                    trust_remote_code=True
                )
                self.exaone_model = AutoModelForCausalLM.from_pretrained(
                    EXAONE_MODEL,
                    torch_dtype=torch.bfloat16,
                    device_map="auto",
                    max_memory={0: MAX_GPU_MEMORY},
                    low_cpu_mem_usage=True,
                    attn_implementation="eager",
                    trust_remote_code=True
                )
                
                # ë¡œì»¬ì— ì €ì¥
                self.exaone_tokenizer.save_pretrained(str(EXAONE_LOCAL_PATH))
                self.exaone_model.save_pretrained(str(EXAONE_LOCAL_PATH))
                logger.info(f"EXAONE saved to: {EXAONE_LOCAL_PATH}")
            
            if self.exaone_tokenizer.pad_token is None:
                self.exaone_tokenizer.pad_token = self.exaone_tokenizer.eos_token
            
            logger.info("âœ… Successfully loaded EXAONE (Investment Insights Generator)")
            self.exaone_available = True
            
        except Exception as e:
            logger.error(f"âŒ Error loading EXAONE: {e}")
            self.exaone_available = False
    
    def _batch_predict_kr_finbert(self, texts, batch_size=BATCH_SIZE):
        """KR-FinBERT ë°°ì¹˜ ì²˜ë¦¬ë¡œ í•œêµ­ì–´ ê¸ˆìœµ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ (1ë‹¨ê³„)"""
        if not self.kr_finbert_available:
            return [self._fallback_analysis(text) for text in texts]
        
        results = []
        
        try:
            logger.info(f"ğŸ¯ KR-FinBERT í•œêµ­ì–´ ê¸ˆìœµ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì‹œì‘: {len(texts)}ê°œ ë‰´ìŠ¤")
            
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i+batch_size]
                
                inputs = self.kr_finbert_tokenizer(
                    batch_texts,
                    return_tensors="pt",
                    padding=True,
                    truncation=True,
                    max_length=128
                ).to(self.device)
                
                with torch.no_grad():
                    outputs = self.kr_finbert_model(**inputs)
                    probabilities = F.softmax(outputs.logits, dim=1)
                    
                    for j, probs in enumerate(probabilities):
                        sentiment_label = torch.argmax(probs).item()
                        sentiment_prob = probs[sentiment_label].item()
                        sentiment_map = {0: 'ë¶€ì •', 1: 'ì¤‘ë¦½', 2: 'ê¸ì •'}
                        
                        results.append({
                            'label': sentiment_label,
                            'sentiment': sentiment_map[sentiment_label],
                            'probability': sentiment_prob,
                            'model_used': 'KR-FinBERT-Korean-Financial-Specialist'
                        })
                
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        except Exception as e:
            logger.error(f"KR-FinBERT ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            for text in texts:
                results.append(self._fallback_analysis(text))
        
        return results
    
    def analyze_dataframe_optimized(self, df, text_column='ì œëª©'):
        """1ë‹¨ê³„: KR-FinBERTë¡œ í•œêµ­ì–´ ê¸ˆìœµ ë‰´ìŠ¤ ê°ì„± ë¶„ë¥˜"""
        logger.info(f"ğŸ¯ 1ë‹¨ê³„ ì‹œì‘: KR-FinBERTë¡œ {len(df)}ê°œ í•œêµ­ì–´ ê¸ˆìœµ ë‰´ìŠ¤ ê°ì„± ë¶„ì„")
        
        texts = df[text_column].tolist()
        batch_results = self._batch_predict_kr_finbert(texts)
        
        df['sentiment_label'] = [r['label'] for r in batch_results]
        df['sentiment'] = [r['sentiment'] for r in batch_results]
        df['sentiment_prob'] = [r['probability'] for r in batch_results]
        df['model_used'] = [r['model_used'] for r in batch_results]
        df['analysis_reason'] = ['KR-FinBERT í•œêµ­ì–´ ê¸ˆìœµ ë„ë©”ì¸ íŠ¹í™” ë¶„ì„' for _ in batch_results]
        df['investment_impact'] = ['2ë‹¨ê³„: EXAONE ì¢…í•© ì¸ì‚¬ì´íŠ¸ ëŒ€ê¸°' for _ in batch_results]
        
        # ë¶„ì„ ê²°ê³¼ ìš”ì•½
        sentiment_counts = df['sentiment'].value_counts()
        total = len(df)
        
        logger.info("=== 1ë‹¨ê³„ ì™„ë£Œ: KR-FinBERT í•œêµ­ì–´ ê¸ˆìœµ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ê²°ê³¼ ===")
        for sentiment, count in sentiment_counts.items():
            percentage = (count / total) * 100
            logger.info(f"{sentiment}: {count}ê°œ ({percentage:.1f}%)")
        
        logger.info(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ: KR-FinBERTê°€ {total}ê°œ í•œêµ­ì–´ ê¸ˆìœµ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì™„ë£Œ")
        logger.info("ğŸ§  2ë‹¨ê³„ ì¤€ë¹„: EXAONEì´ ê°ì„± ê²°ê³¼ì™€ ì°¨íŠ¸ë¥¼ ì¢…í•©í•˜ì—¬ íˆ¬ì ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜ˆì •")
        
        return df
    
    def generate_comprehensive_investment_insight(self, news_sentiment_summary, stock_price_data, company_name, news_titles, chart_trend=None):
        """2ë‹¨ê³„: EXAONEì´ KR-FinBERT ê°ì„± ê²°ê³¼ + ì°¨íŠ¸ â†’ íˆ¬ì ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        if not self.exaone_available:
            return self._simple_recommendation_from_kr_finbert_summary(news_sentiment_summary, stock_price_data)
        
        try:
            logger.info(f"ğŸ§  2ë‹¨ê³„ ì‹œì‘: EXAONEì´ KR-FinBERT ê²°ê³¼ì™€ ì°¨íŠ¸ë¥¼ ì¢…í•©í•˜ì—¬ {company_name} íˆ¬ì ì¸ì‚¬ì´íŠ¸ ìƒì„±")
            
            positive_count = news_sentiment_summary.get('positive_count', 0)
            negative_count = news_sentiment_summary.get('negative_count', 0)
            neutral_count = news_sentiment_summary.get('neutral_count', 0)
            total_news = positive_count + negative_count + neutral_count
            
            if total_news == 0:
                return {
                    "recommendation": "ë³´ë¥˜", 
                    "reason": "KR-FinBERTê°€ ë¶„ì„í•  ë‰´ìŠ¤ê°€ ì—†ì–´ EXAONE ì¸ì‚¬ì´íŠ¸ ìƒì„± ë¶ˆê°€", 
                    "ai_generated": False,
                    "analysis_stage": "1ë‹¨ê³„ ë°ì´í„° ë¶€ì¡±"
                }
            
            # ê°ì„± ë¹„ìœ¨ ê³„ì‚°
            total_relevant = positive_count + negative_count
            positive_ratio = (positive_count / total_relevant * 100) if total_relevant > 0 else 50
            negative_ratio = (negative_count / total_relevant * 100) if total_relevant > 0 else 50
            
            current_price = stock_price_data.get('current_price', 'N/A')
            change_rate = stock_price_data.get('change_rate', 'N/A')
            status = stock_price_data.get('status', 'ë³´í•©')
            
            top_news_titles = news_titles[:3] if news_titles else []
            
            # ì°¨íŠ¸ íŠ¸ë Œë“œ ì •ë³´
            chart_info = ""
            if chart_trend:
                chart_info = f"ì°¨íŠ¸ íŠ¸ë Œë“œ: {chart_trend}"
            
            # ê°œì„ ëœ EXAONEìš© í”„ë¡¬í”„íŠ¸ (ê°ì„± ë¹„ìœ¨ ëª…ì‹œ ë° ë…¼ë¦¬ì  ì¼ê´€ì„± ê°•í™”)
            prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name}ì— ëŒ€í•œ íˆ¬ì íŒë‹¨ì„ í•´ì£¼ì„¸ìš”.

ã€ë¶„ì„ ì •ë³´ã€‘
â€¢ KR-FinBERT ê°ì„± ë¶„ì„ ê²°ê³¼
  - ê¸ì • ë‰´ìŠ¤: {positive_count}ê°œ ({positive_ratio:.1f}%)
  - ë¶€ì • ë‰´ìŠ¤: {negative_count}ê°œ ({negative_ratio:.1f}%)
  - ì¤‘ë¦½ ë‰´ìŠ¤: {neutral_count}ê°œ
  - ì´ ë‰´ìŠ¤: {total_news}ê°œ
  - ê°ì„± ê²½í–¥: {'ë¶€ì •ì ' if negative_ratio > 60 else 'ê¸ì •ì ' if positive_ratio > 60 else 'ì¤‘ë¦½ì '}

â€¢ ì£¼ê°€ ì •ë³´
  - í˜„ì¬ê°€: {current_price}ì›
  - ë³€ë™ë¥ : {change_rate}
  - ìƒíƒœ: {status}
  - {chart_info}

â€¢ ì£¼ìš” ë‰´ìŠ¤
{chr(10).join([f"  - {title}" for title in top_news_titles])}

ã€ë¶„ì„ ê°€ì´ë“œë¼ì¸ã€‘
1. ë‰´ìŠ¤ ê°ì„±ì´ 60% ì´ìƒ ë¶€ì •ì ì´ë©´ ë§¤ë„ ê³ ë ¤
2. ë‰´ìŠ¤ ê°ì„±ì´ 60% ì´ìƒ ê¸ì •ì ì´ë©´ ë§¤ìˆ˜ ê³ ë ¤
3. ë‰´ìŠ¤ ê°ì„±ì´ í˜¼ì¬ëœ ê²½ìš° ì°¨íŠ¸ íŠ¸ë Œë“œ ì¤‘ì  ê³ ë ¤
4. ë‰´ìŠ¤ì™€ ì°¨íŠ¸ê°€ ìƒì¶©í•  ê²½ìš° ë³´ìˆ˜ì  ì ‘ê·¼

ã€ìš”ì²­ì‚¬í•­ã€‘
ìœ„ ì •ë³´ì™€ ê°€ì´ë“œë¼ì¸ì„ ì¢…í•©í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

íˆ¬ìì¶”ì²œ: ë§¤ìˆ˜/ë³´ë¥˜/ë§¤ë„ ì¤‘ í•˜ë‚˜
í™•ì‹ ë„: 1~10ì  ì¤‘ í•˜ë‚˜  
ë¶„ì„ê·¼ê±°: ë‰´ìŠ¤ ê°ì„± ë¹„ìœ¨ê³¼ ì°¨íŠ¸ ì •ë³´ë¥¼ ì—°ê²°í•œ êµ¬ì²´ì ì¸ íˆ¬ì íŒë‹¨ ì´ìœ ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…

ë‹µë³€:"""

            inputs = self.exaone_tokenizer(prompt, return_tensors="pt", max_length=1024, truncation=True)
            if self.device.type == 'cuda':
                inputs = inputs.to(self.device)
            
            with torch.no_grad():
                outputs = self.exaone_model.generate(
                    **inputs,
                    max_new_tokens=150,
                    temperature=0.2,
                    do_sample=True,
                    top_p=0.8,
                    repetition_penalty=1.2,
                    pad_token_id=self.exaone_tokenizer.eos_token_id,
                    eos_token_id=self.exaone_tokenizer.eos_token_id
                )
            
            input_length = inputs['input_ids'].shape[1]
            generated_tokens = outputs[0][input_length:]
            response = self.exaone_tokenizer.decode(generated_tokens, skip_special_tokens=True)
            
            logger.info("âœ… 2ë‹¨ê³„ ì™„ë£Œ: EXAONEì´ KR-FinBERT ê²°ê³¼ì™€ ì°¨íŠ¸ë¥¼ ì¢…í•©í•œ íˆ¬ì ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ")
            
            return self._parse_comprehensive_insight(response, news_sentiment_summary, stock_price_data)
            
        except Exception as e:
            logger.error(f"EXAONE 2ë‹¨ê³„ ì¢…í•© ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._simple_recommendation_from_kr_finbert_summary(news_sentiment_summary, stock_price_data)
    
    def _parse_comprehensive_insight(self, response, sentiment_summary, stock_data):
        """EXAONE ì¢…í•© ì¸ì‚¬ì´íŠ¸ ì‘ë‹µ íŒŒì‹±"""
        try:
            response = response.strip()
            logger.info(f"EXAONE ì›ë³¸ ì‘ë‹µ: {response}")
            
            # íˆ¬ìì¶”ì²œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ê°•ì¡° êµ¬ë¬¸ê³¼ íŒŒì´í”„ êµ¬ë¶„ì ì²˜ë¦¬)
            recommendation = "ë³´ë¥˜"
            rec_patterns = [
                r'íˆ¬ìì¶”ì²œ[:\s]*\*\*([ë§¤ìˆ˜ë§¤ë„ë³´ë¥˜]+)\*\*[\s|]*',  # ** ê°•ì¡° êµ¬ë¬¸ì´ ìˆëŠ” ê²½ìš° (íŒŒì´í”„ í¬í•¨)
                r'íˆ¬ìì¶”ì²œ[:\s]*([ë§¤ìˆ˜ë§¤ë„ë³´ë¥˜]+)[\s|]*',          # ì¼ë°˜ í…ìŠ¤íŠ¸ (íŒŒì´í”„ í¬í•¨)
                r'íˆ¬ìì¶”ì²œ[:\s]*\*\*([ë§¤ìˆ˜ë§¤ë„ë³´ë¥˜]+)\*\*',       # ** ê°•ì¡° êµ¬ë¬¸ë§Œ ìˆëŠ” ê²½ìš°
                r'íˆ¬ìì¶”ì²œ[:\s]*([ë§¤ìˆ˜ë§¤ë„ë³´ë¥˜]+)'                # ì¼ë°˜ í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê²½ìš°
            ]
            
            for pattern in rec_patterns:
                rec_match = re.search(pattern, response)
                if rec_match:
                    rec_text = rec_match.group(1)
                    if 'ë§¤ìˆ˜' in rec_text:
                        recommendation = "ë§¤ìˆ˜"
                    elif 'ë§¤ë„' in rec_text:
                        recommendation = "ë§¤ë„"
                    else:
                        recommendation = "ë³´ë¥˜"
                    break
            
            # í™•ì‹ ë„ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ê°•ì¡° êµ¬ë¬¸ê³¼ íŒŒì´í”„ êµ¬ë¶„ì ì²˜ë¦¬)
            confidence = 0.7
            conf_patterns = [
                r'í™•ì‹ ë„[:\s]*\*\*(\d+)\*\*[\s|]*',  # ** ê°•ì¡° êµ¬ë¬¸ì´ ìˆëŠ” ê²½ìš° (íŒŒì´í”„ í¬í•¨)
                r'í™•ì‹ ë„[:\s]*(\d+)[\s|]*',          # ì¼ë°˜ í…ìŠ¤íŠ¸ (íŒŒì´í”„ í¬í•¨)
                r'í™•ì‹ ë„[:\s]*\*\*(\d+)\*\*',        # ** ê°•ì¡° êµ¬ë¬¸ë§Œ ìˆëŠ” ê²½ìš°
                r'í™•ì‹ ë„[:\s]*(\d+)',                # ì¼ë°˜ í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê²½ìš°
                r'í™•ì‹ ë„[:\s]*(\d+(?:\.\d+)?%)'      # ë°±ë¶„ìœ¨ í˜•ì‹
            ]
            
            for pattern in conf_patterns:
                conf_match = re.search(pattern, response)
                if conf_match:
                    conf_value = conf_match.group(1)
                    if '%' in conf_value:
                        confidence = float(conf_value.rstrip('%')) / 100
                    else:
                        confidence = min(max(int(conf_value) / 10, 0.1), 1.0)
                    break
            
            # ë¶„ì„ê·¼ê±° ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ê°•ì¡° êµ¬ë¬¸ ìœ ì§€)
            reason = "EXAONE ì¢…í•© ë¶„ì„ ê²°ê³¼"
            reason_patterns = [
                r'ë¶„ì„ê·¼ê±°[:\s]*\*\*(.+?)\*\*(?=\s*(?:\||$))',  # ** ê°•ì¡° êµ¬ë¬¸ì´ ìˆëŠ” ê²½ìš° (íŒŒì´í”„ í¬í•¨)
                r'ë¶„ì„ê·¼ê±°[:\s]*(.+?)(?=\s*(?:\||$))',          # ì¼ë°˜ í…ìŠ¤íŠ¸ (íŒŒì´í”„ í¬í•¨)
                r'ë¶„ì„ê·¼ê±°[:\s]*(.+)',                          # ì „ì²´ í…ìŠ¤íŠ¸
            ]
            
            for pattern in reason_patterns:
                reason_match = re.search(pattern, response, re.DOTALL)
                if reason_match:
                    reason = reason_match.group(1).strip()
                    break
            
            if not reason or len(reason.strip()) < 10:
                reason = f"KR-FinBERTê°€ ë¶„ì„í•œ ê¸ì • {sentiment_summary.get('positive_count', 0)}ê°œ, ë¶€ì • {sentiment_summary.get('negative_count', 0)}ê°œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ EXAONE ì¢…í•© íŒë‹¨"
            
            return {
                "recommendation": recommendation,
                "confidence": confidence,
                "reason": reason,
                "ai_generated": True,
                "model_used": "EXAONE-Improved",
                "analysis_stage": "2ë‹¨ê³„ ì™„ë£Œ: KR-FinBERT + ì°¨íŠ¸ ì¢…í•©",
                "original_response": response  # ì›ë³¸ ì‘ë‹µ í¬í•¨
            }
            
        except Exception as e:
            logger.error(f"EXAONE ì¸ì‚¬ì´íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {
                "recommendation": "ë³´ë¥˜",
                "confidence": 0.5,
                "reason": "EXAONE ë¶„ì„ ì¤‘ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ",
                "ai_generated": False,
                "analysis_stage": "2ë‹¨ê³„ íŒŒì‹± ì˜¤ë¥˜",
                "original_response": response  # ì˜¤ë¥˜ ì‹œì—ë„ ì›ë³¸ ì‘ë‹µ í¬í•¨
            }
    
    def _simple_recommendation_from_kr_finbert_summary(self, news_sentiment_summary, stock_price_data):
        """KR-FinBERT ê°ì„± ìš”ì•½ ê¸°ë°˜ ê°„ë‹¨í•œ ì¶”ì²œ (EXAONE ì‹¤íŒ¨ ì‹œ)"""
        positive_count = news_sentiment_summary.get('positive_count', 0)
        negative_count = news_sentiment_summary.get('negative_count', 0)
        total_relevant = positive_count + negative_count
        
        if total_relevant == 0:
            return {
                "recommendation": "ë³´ë¥˜",
                "confidence": 0.5,
                "reason": "KR-FinBERT ë¶„ì„ ê²°ê³¼ ëª…í™•í•œ ê°ì„± ì‹ í˜¸ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "ai_generated": False,
                "analysis_stage": "1ë‹¨ê³„ë§Œ ì™„ë£Œ: KR-FinBERT ê°ì„± ë¶„ì„"
            }
        
        sentiment_ratio = positive_count / total_relevant
        
        if sentiment_ratio > 0.7:
            return {
                "recommendation": "ë§¤ìˆ˜",
                "confidence": 0.8,
                "reason": f"KR-FinBERT ë¶„ì„ ê²°ê³¼ ê¸ì • ë‰´ìŠ¤ ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤ ({positive_count}/{total_relevant})",
                "ai_generated": False,
                "analysis_stage": "1ë‹¨ê³„ë§Œ ì™„ë£Œ: KR-FinBERT ê°ì„± ë¶„ì„"
            }
        elif sentiment_ratio < 0.3:
            return {
                "recommendation": "ë§¤ë„",
                "confidence": 0.8,
                "reason": f"KR-FinBERT ë¶„ì„ ê²°ê³¼ ë¶€ì • ë‰´ìŠ¤ ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤ ({negative_count}/{total_relevant})",
                "ai_generated": False,
                "analysis_stage": "1ë‹¨ê³„ë§Œ ì™„ë£Œ: KR-FinBERT ê°ì„± ë¶„ì„"
            }
        else:
            return {
                "recommendation": "ë³´ë¥˜",
                "confidence": 0.6,
                "reason": "KR-FinBERT ë¶„ì„ ê²°ê³¼ ë‰´ìŠ¤ ê°ì„±ì´ í˜¼ì¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                "ai_generated": False,
                "analysis_stage": "1ë‹¨ê³„ë§Œ ì™„ë£Œ: KR-FinBERT ê°ì„± ë¶„ì„"
            }
    
    def _fallback_analysis(self, text):
        """ëª¨ë“  AI ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ë¶„ì„"""
        return {
            'label': 1,
            'sentiment': 'ì¤‘ë¦½',
            'probability': 0.5,
            'model_used': 'Fallback-Analysis'
        }
    
    # ê¸°ì¡´ í˜¸í™˜ì„± ë©”ì„œë“œë“¤
    def analyze_dataframe(self, df, text_column='ì œëª©', use_exaone=False):
        return self.analyze_dataframe_optimized(df, text_column)
    
    def generate_trading_recommendation(self, news_data, stock_price_data, company_name):
        if not news_data:
            news_sentiment_summary = {
                'positive_count': 0,
                'negative_count': 0,
                'neutral_count': 0,
                'top_news': []
            }
        else:
            positive_count = len([n for n in news_data if n.get('sentiment') == 'ê¸ì •'])
            negative_count = len([n for n in news_data if n.get('sentiment') == 'ë¶€ì •'])
            neutral_count = len([n for n in news_data if n.get('sentiment') == 'ì¤‘ë¦½'])
            top_news = [n.get('ì œëª©', n.get('title', '')) for n in news_data[:5]]
            
            news_sentiment_summary = {
                'positive_count': positive_count,
                'negative_count': negative_count,
                'neutral_count': neutral_count,
                'top_news': top_news
            }
        
        return self.generate_comprehensive_investment_insight(news_sentiment_summary, stock_price_data, company_name, news_sentiment_summary.get('top_news', []))